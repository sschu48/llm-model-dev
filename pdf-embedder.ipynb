{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Document Embedding Tool\n",
    "\n",
    "This is a fork from the retrieval-v1 within the local-rag development.\n",
    "\n",
    "In this notebook the goal is to design an approach to load content from a PDF document into an vector database. For this experiment we will use Pinecone because it will most likely be our weapon of choice during production grade development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanschumacher/opt/miniconda3/envs/llama-index/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "import os\n",
    "import requests\n",
    "from tqdm.auto import tqdm # for progress bars\n",
    "import random\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract content from PDFs\n",
    "\n",
    "data will be extracted from each pdf file we load in. The content can vary from text to images to tables. We will need to continue to develop different function to accurately load this into our notebook.\n",
    "\n",
    "The text is cleaned before being populated to remove any noise. This will help increase accuracy of embeddings further down the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Document Loader\n",
    "\n",
    "import pymupdf\n",
    "\n",
    "# extract image from pdf\n",
    "def get_page_images(doc, page_content, page_index):\n",
    "    image_paths = []\n",
    "    try:\n",
    "        image_list = page_content.get_images()\n",
    "\n",
    "        # print number of images found on page\n",
    "        if image_list: \n",
    "            print(f\"found {len(image_list)} images on page {page_index}\")\n",
    "\n",
    "        for image_index, img in enumerate(image_list, start=1): # enumerate the image list\n",
    "            xref = img[0] # get XREF of image\n",
    "            pix = pymupdf.Pixmap(doc, xref) # create a Pixmap\n",
    "\n",
    "            if pix.n - pix.alpha > 3: #CMYK: convert to RGB first\n",
    "                pix = pymupdf.Pixmap(pymupdf.cdRGB, pix)\n",
    "\n",
    "            image_path = \"page_%s-image_%s.png\" % (page_index, image_index)\n",
    "            pix.save(image_path) # save the image as png\n",
    "            pix = None\n",
    "\n",
    "            image_paths.append(image_path)\n",
    "\n",
    "    except Exception as e: \n",
    "        print(f\"error occurred getting images: {e}\")\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# clean text\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Format text to remove noise.\n",
    "\n",
    "    In the document we are experimenting with, there are a lot of \".\"s\n",
    "    We will also move \"\\n\" and replace with \" \"\n",
    "    \"\"\"\n",
    "\n",
    "    # replace multiple dots (.............) with a single space\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)\n",
    "\n",
    "    # replace new line character with space\n",
    "    clean_text = text.replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    # Add more formatting if needed\n",
    "    return clean_text\n",
    "\n",
    "# parse document\n",
    "def parse_document(filepath):\n",
    "    \"\"\"\n",
    "    This will extract all the data from document and \n",
    "    populate a dictionary with the extracted data\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---PARSING DOCUMENT---\")\n",
    "    doc = pymupdf.open(filepath) # open document\n",
    "    pages_and_texts = []\n",
    "\n",
    "    for page_number, page in enumerate(doc):\n",
    "        text = page.get_text() # get text from page\n",
    "        text = clean_text(text) # clean text\n",
    "        pages_and_texts.append({\n",
    "            \"page_number\": page_number,\n",
    "            \"page_char_count\": len(text),\n",
    "            \"page_word_count\": len(text.split(\" \")),\n",
    "            \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "            \"page_token_count\": len(text) / 4, # average token = ~4 char\n",
    "            \"images\": get_page_images(doc, page, page_number),\n",
    "            \"text\": text,\n",
    "        })\n",
    "\n",
    "    return pages_and_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run 'parse_document' to extract data from local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./raw-data/61-65 Certifications.pdf\"\n",
    "\n",
    "# parse document\n",
    "pdf_content = parse_document(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully retrieved the content from the PDF document.\n",
    "\n",
    "Now this content needs to be broken down into chunks that will fit into the context window of our llm.\n",
    "\n",
    "We will use spaCy to break text into sentences. Its an NLP library, therefore, it will be more accurate than splitting by: text.split(\". \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "# initialize model and sentincizer once \n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "def chunk_content(content):\n",
    "    for item in tqdm(content):\n",
    "        # Process the text to get sentences\n",
    "        doc = nlp(item[\"text\"])\n",
    "        item[\"sentences\"] = list(doc.sents)\n",
    "\n",
    "        # Convert sentences to strings\n",
    "        item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "\n",
    "        # Count the sentences\n",
    "        item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])\n",
    "\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_content = chunk_content(pdf_content)\n",
    "\n",
    "# inspect sample\n",
    "random.sample(pdf_content, k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split size\n",
    "sentences_in_chunk = 10\n",
    "\n",
    "# recursively split list into desired sizes\n",
    "def split_list(input_list: list,\n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Split the input_list into sublists of size slice_size (as close as possible)\n",
    "    \"\"\"\n",
    "\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# looper through pages and text and split sentences into chunks\n",
    "for item in tqdm(pdf_content):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                          slice_size=sentences_in_chunk)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample example from group\n",
    "random.sample(pdf_content, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pdf_content):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "\n",
    "        # join sentences together into a paragraph-like structure, aka a chunk (single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full stop/capital letter combo\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # get stats about chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 char\n",
    "\n",
    "        pages_and_chunks.append(chunk_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view random sample\n",
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove smaller embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "\n",
    "# show random chunks with under 10 tokens in length\n",
    "min_token_length = 10\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(1).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]} | Page number: {row[1][\"page_number\"]}')\n",
    "\n",
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding text chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
    "                                      device=\"cpu\") # choose device to load model to\n",
    "\n",
    "# Notes: this will embed using local computing power. Learn more about the benefits (if any)\n",
    "# of computing in the cloud\n",
    "\n",
    "# Make sure the model is on the CPU\n",
    "embedding_model.to(\"cpu\")\n",
    "\n",
    "# Embed each chunk one by one\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_and_chunks_over_min_token_len[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save to file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to Pinecone\n",
    "\n",
    "Using Pinecone will allow us to retrieve documents seamlessly. These embeddings will be continuously stored elsewhere so they can be retrieved whenever\n",
    "\n",
    "First we will need to initialize a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connection\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
    "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"rag-retriever-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if index already exists\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",\n",
    "        spec=spec,\n",
    "    )\n",
    "#connect to index\n",
    "index = pc.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ids for embeddings\n",
    "for item in range(len(pages_and_chunks_over_min_token_len)):\n",
    "    pages_and_chunks_over_min_token_len[item][\"ids\"] = str(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_and_chunks_over_min_token_len[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "batch_size = 100 # amount of embeddings to create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(pages_and_chunks_over_min_token_len), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(pages_and_chunks_over_min_token_len), i+batch_size)\n",
    "    meta_batch = pages_and_chunks_over_min_token_len[i:i_end]\n",
    "    # get ids\n",
    "    ids_branch = [x[\"ids\"] for x in meta_batch]\n",
    "    # get text to encode\n",
    "    text_branch = [x[\"sentence_chunk\"] for x in meta_batch]\n",
    "    # get embedding\n",
    "    embeddings = [x[\"embedding\"] for x in meta_batch]\n",
    "\n",
    "    # clean metadata\n",
    "    meta_batch = [{\n",
    "        \"text\": x[\"sentence_chunk\"],\n",
    "        \"ids\": x[\"ids\"],\n",
    "        \"page_number\": x[\"page_number\"],\n",
    "        \"chunk_char_count\": x[\"chunk_char_count\"],\n",
    "        \"chunk_word_count\": x[\"chunk_word_count\"],\n",
    "        \"chunk_token_count\": x[\"chunk_token_count\"],\n",
    "    } for x in meta_batch]\n",
    "    # upsert to pinecone\n",
    "    to_upsert = list(zip(ids_branch, embeddings, meta_batch))\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are now uploaded into pincone with the necessary metadata.\n",
    "\n",
    "We can confirm the accuracy between the notebook variables and pinecone by searching for ids\n",
    "\n",
    "Embedding our query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what do i need to sign for a student to solo?\"\n",
    "res = embedding_model.encode(query)\n",
    "\n",
    "xq = res.tolist()\n",
    "\n",
    "res = index.query(vector=xq, top_k=2, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve relevant documents by finding items that are similar to our query.\n",
    "\n",
    "Now, we will put this into a retrieval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 3750\n",
    "\n",
    "def retrieve(query):\n",
    "    res = embedding_model.encode(query)\n",
    "\n",
    "    # retrieve from Pinecone\n",
    "    xq = res.tolist()\n",
    "\n",
    "    # get relevant documents\n",
    "    res = index.query(vector=xq, top_k=2, include_metadata=True)\n",
    "    contexts = [\n",
    "        x['metadata']['text'] for x in res['matches']\n",
    "    ]\n",
    "\n",
    "    # build our prompt with the retrieved context included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below. \\n\\n\"+\n",
    "        \"Context: \\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append context until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start + \n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start + \n",
    "                \"\\n\\n---\\n\\n\".join(contexts) + \n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we retrieve relevant items from pinecone\n",
    "query_with_context = retrieve(query)\n",
    "print(query_with_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using OpenAI for LLM\n",
    "\n",
    "For our generator we will use OpenAI's API to create content. This cna be local down the road if needed, but for now this is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "# Define the query as a list of message objects\n",
    "query = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what is an airplane?\"}\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=query\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(prompt):\n",
    "    query = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=query\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "query = \"what do i need to sign for a student to solo?\"\n",
    "\n",
    "print(complete(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete(query_with_context))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
